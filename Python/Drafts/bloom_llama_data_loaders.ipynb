{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama-index with custom LLm \n",
    "Previously, we used llama-index (which rely on openai to create word embeddings by default) with a custom llm and created a vector index by manually creating and loading Documents from the dataset. In this notebook, I test various data loaders methods from llama-index and compare their result. Since our data contains texts and tabular data, we need to either load the whole data (from pdf or html page) or partition text and tabular data and build indices for each one. See here for more info https://gpt-index.readthedocs.io/en/latest/how_to/index_structs/composability.html, and see demo here https://github.com/jerryjliu/llama_index/blob/main/examples/composable_indices/ComposableIndices.ipynb.\n",
    "\n",
    "We can also choose other supported transformers to create embeddings. See here for more info. https://gpt-index.readthedocs.io/en/latest/how_to/customization/embeddings.html#custom-embeddings. I have another notebook where I tested the custom-embeddings.\n",
    "\n",
    "We can also use llama-index with langchain agent which can do more complex data structures. See here for more info https://gpt-index.readthedocs.io/en/latest/how_to/integrations/using_with_langchain.html, and usage here https://github.com/jerryjliu/llama_index/blob/main/examples/chatbot/Chatbot_SEC.ipynb. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WiVAOY7t991j"
   },
   "source": [
    "What we are developing here is called generative question-answering model using indexing library llama-index and text generation Bloom model.\n",
    "- https://wandb.ai/mostafaibrahim17/ml-articles/reports/The-Answer-Key-Unlocking-the-Potential-of-Question-Answering-With-NLP--VmlldzozNTcxMDE3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uSkcOdxXCfRs",
    "outputId": "2515ba80-5ee9-4b37-8f86-7e36608a4b64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./.conda/envs/default/lib/python3.9/site-packages (23.1.2)\n",
      "Requirement already satisfied: llama_index in ./.conda/envs/default/lib/python3.9/site-packages (0.5.25)\n",
      "Requirement already satisfied: dataclasses-json in ./.conda/envs/default/lib/python3.9/site-packages (from llama_index) (0.5.7)\n",
      "Requirement already satisfied: langchain==0.0.142 in ./.conda/envs/default/lib/python3.9/site-packages (from llama_index) (0.0.142)\n",
      "Requirement already satisfied: numpy in ./.conda/envs/default/lib/python3.9/site-packages (from llama_index) (1.23.5)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in ./.conda/envs/default/lib/python3.9/site-packages (from llama_index) (8.2.2)\n",
      "Requirement already satisfied: openai>=0.26.4 in ./.conda/envs/default/lib/python3.9/site-packages (from llama_index) (0.27.2)\n",
      "Requirement already satisfied: pandas in ./.conda/envs/default/lib/python3.9/site-packages (from llama_index) (1.5.3)\n",
      "Requirement already satisfied: tiktoken in ./.conda/envs/default/lib/python3.9/site-packages (from llama_index) (0.3.2)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in ./.conda/envs/default/lib/python3.9/site-packages (from langchain==0.0.142->llama_index) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in ./.conda/envs/default/lib/python3.9/site-packages (from langchain==0.0.142->llama_index) (1.4.47)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.conda/envs/default/lib/python3.9/site-packages (from langchain==0.0.142->llama_index) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./.conda/envs/default/lib/python3.9/site-packages (from langchain==0.0.142->llama_index) (4.0.2)\n",
      "Requirement already satisfied: gptcache>=0.1.7 in ./.conda/envs/default/lib/python3.9/site-packages (from langchain==0.0.142->llama_index) (0.1.11)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in ./.conda/envs/default/lib/python3.9/site-packages (from langchain==0.0.142->llama_index) (2.8.4)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in ./.conda/envs/default/lib/python3.9/site-packages (from langchain==0.0.142->llama_index) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in ./.conda/envs/default/lib/python3.9/site-packages (from langchain==0.0.142->llama_index) (1.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.conda/envs/default/lib/python3.9/site-packages (from langchain==0.0.142->llama_index) (2.28.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in ./.conda/envs/default/lib/python3.9/site-packages (from dataclasses-json->llama_index) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in ./.conda/envs/default/lib/python3.9/site-packages (from dataclasses-json->llama_index) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in ./.conda/envs/default/lib/python3.9/site-packages (from dataclasses-json->llama_index) (0.8.0)\n",
      "Requirement already satisfied: tqdm in ./.conda/envs/default/lib/python3.9/site-packages (from openai>=0.26.4->llama_index) (4.65.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.conda/envs/default/lib/python3.9/site-packages (from pandas->llama_index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.conda/envs/default/lib/python3.9/site-packages (from pandas->llama_index) (2022.7.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.conda/envs/default/lib/python3.9/site-packages (from tiktoken->llama_index) (2022.10.31)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.conda/envs/default/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->llama_index) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./.conda/envs/default/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->llama_index) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.conda/envs/default/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->llama_index) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.conda/envs/default/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->llama_index) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.conda/envs/default/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->llama_index) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.conda/envs/default/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142->llama_index) (1.3.1)\n",
      "Requirement already satisfied: cachetools in ./.conda/envs/default/lib/python3.9/site-packages (from gptcache>=0.1.7->langchain==0.0.142->llama_index) (5.3.0)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.conda/envs/default/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama_index) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./.conda/envs/default/lib/python3.9/site-packages (from pydantic<2,>=1->langchain==0.0.142->llama_index) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->llama_index) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.0.142->llama_index) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.0.142->llama_index) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.0.142->llama_index) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.conda/envs/default/lib/python3.9/site-packages (from SQLAlchemy<2,>=1->langchain==0.0.142->llama_index) (2.0.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.conda/envs/default/lib/python3.9/site-packages (from typing-inspect>=0.4.0->dataclasses-json->llama_index) (1.0.0)\n",
      "Requirement already satisfied: transformers in ./.conda/envs/default/lib/python3.9/site-packages (4.28.1)\n",
      "Requirement already satisfied: filelock in ./.conda/envs/default/lib/python3.9/site-packages (from transformers) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in ./.conda/envs/default/lib/python3.9/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.conda/envs/default/lib/python3.9/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/envs/default/lib/python3.9/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.conda/envs/default/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.conda/envs/default/lib/python3.9/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in ./.conda/envs/default/lib/python3.9/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./.conda/envs/default/lib/python3.9/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.conda/envs/default/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.conda/envs/default/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/envs/default/lib/python3.9/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/envs/default/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.conda/envs/default/lib/python3.9/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/envs/default/lib/python3.9/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: panda in ./.conda/envs/default/lib/python3.9/site-packages (0.3.1)\n",
      "Requirement already satisfied: setuptools in ./.conda/envs/default/lib/python3.9/site-packages (from panda) (65.5.1)\n",
      "Requirement already satisfied: requests in ./.conda/envs/default/lib/python3.9/site-packages (from panda) (2.28.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/envs/default/lib/python3.9/site-packages (from requests->panda) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/envs/default/lib/python3.9/site-packages (from requests->panda) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.conda/envs/default/lib/python3.9/site-packages (from requests->panda) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/envs/default/lib/python3.9/site-packages (from requests->panda) (2022.12.7)\n",
      "Requirement already satisfied: numpy in ./.conda/envs/default/lib/python3.9/site-packages (1.23.5)\n",
      "Requirement already satisfied: torch in ./.conda/envs/default/lib/python3.9/site-packages (1.13.1)\n",
      "Requirement already satisfied: torchvision in ./.conda/envs/default/lib/python3.9/site-packages (0.14.1)\n",
      "Requirement already satisfied: torchaudio in ./.conda/envs/default/lib/python3.9/site-packages (0.13.1)\n",
      "Requirement already satisfied: typing-extensions in ./.conda/envs/default/lib/python3.9/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./.conda/envs/default/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./.conda/envs/default/lib/python3.9/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./.conda/envs/default/lib/python3.9/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./.conda/envs/default/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: setuptools in ./.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.5.1)\n",
      "Requirement already satisfied: wheel in ./.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: numpy in ./.conda/envs/default/lib/python3.9/site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: requests in ./.conda/envs/default/lib/python3.9/site-packages (from torchvision) (2.28.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.conda/envs/default/lib/python3.9/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: langchain==0.0.142 in ./.conda/envs/default/lib/python3.9/site-packages (0.0.142)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in ./.conda/envs/default/lib/python3.9/site-packages (from langchain==0.0.142) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in ./.conda/envs/default/lib/python3.9/site-packages (from langchain==0.0.142) (1.4.47)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.conda/envs/default/lib/python3.9/site-packages (from langchain==0.0.142) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./.conda/envs/default/lib/python3.9/site-packages (from langchain==0.0.142) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in ./.conda/envs/default/lib/python3.9/site-packages (from langchain==0.0.142) (0.5.7)\n",
      "Requirement already satisfied: gptcache>=0.1.7 in ./.conda/envs/default/lib/python3.9/site-packages (from langchain==0.0.142) (0.1.11)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in ./.conda/envs/default/lib/python3.9/site-packages (from langchain==0.0.142) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.conda/envs/default/lib/python3.9/site-packages (from langchain==0.0.142) (1.23.5)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in ./.conda/envs/default/lib/python3.9/site-packages (from langchain==0.0.142) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in ./.conda/envs/default/lib/python3.9/site-packages (from langchain==0.0.142) (1.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.conda/envs/default/lib/python3.9/site-packages (from langchain==0.0.142) (2.28.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in ./.conda/envs/default/lib/python3.9/site-packages (from langchain==0.0.142) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.conda/envs/default/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./.conda/envs/default/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.conda/envs/default/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.conda/envs/default/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.conda/envs/default/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.conda/envs/default/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in ./.conda/envs/default/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.142) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in ./.conda/envs/default/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.142) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in ./.conda/envs/default/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.142) (0.8.0)\n",
      "Requirement already satisfied: openai in ./.conda/envs/default/lib/python3.9/site-packages (from gptcache>=0.1.7->langchain==0.0.142) (0.27.2)\n",
      "Requirement already satisfied: cachetools in ./.conda/envs/default/lib/python3.9/site-packages (from gptcache>=0.1.7->langchain==0.0.142) (5.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./.conda/envs/default/lib/python3.9/site-packages (from pydantic<2,>=1->langchain==0.0.142) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.0.142) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.0.142) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.0.142) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.conda/envs/default/lib/python3.9/site-packages (from SQLAlchemy<2,>=1->langchain==0.0.142) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.conda/envs/default/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.142) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.conda/envs/default/lib/python3.9/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.142) (1.0.0)\n",
      "Requirement already satisfied: tqdm in ./.conda/envs/default/lib/python3.9/site-packages (from openai->gptcache>=0.1.7->langchain==0.0.142) (4.65.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip\n",
    "!pip install -U llama_index\n",
    "!pip install -U transformers\n",
    "!pip install panda\n",
    "!pip install numpy\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install -U langchain==0.0.142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Dpyu_2GYCkI5"
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "# from llama_index import GPTSimpleVectorIndex, Document, SimpleDirectoryReader\n",
    "import pandas as pd, numpy as np\n",
    "import os, openai\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'your openai key here'\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Preparing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 755
    },
    "id": "Pw3EV9LwnjM_",
    "outputId": "3c8dc707-9f6c-456c-e8f2-b17bee1a7df2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>chapter</th>\n",
       "      <th>article</th>\n",
       "      <th>title</th>\n",
       "      <th>paragraphText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'$oid': '6417c99c2d49ca2fefed951e'}</td>\n",
       "      <td>Chapter 17.5. Lead and Copper</td>\n",
       "      <td>Article 8. Lead Service Line Requirements for ...</td>\n",
       "      <td>§ 64688. Lead Service Line Replacement.</td>\n",
       "      <td>(a) A system shall replace lead service lines ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'$oid': '6417c99c2d49ca2fefed951f'}</td>\n",
       "      <td>Chapter 17.5. Lead and Copper</td>\n",
       "      <td>Article 7. Public Education Program for Lead A...</td>\n",
       "      <td>§ 64687. Lead Public Education Program Content...</td>\n",
       "      <td>(a) Each system with a lead action level excee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'$oid': '6417c99c2d49ca2fefed9520'}</td>\n",
       "      <td>Chapter 17.5. Lead and Copper</td>\n",
       "      <td>Article 8. Lead Service Line Requirements for ...</td>\n",
       "      <td>§ 64689. Lead Service Line Sampling.</td>\n",
       "      <td>(a) Each lead service line sample shall be one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'$oid': '6417c99d2d49ca2fefed9521'}</td>\n",
       "      <td>Chapter 17.5. Lead and Copper</td>\n",
       "      <td>Article 6. Source Water Requirements for Actio...</td>\n",
       "      <td>§ 64686. Requirements Subsequent to the Depart...</td>\n",
       "      <td>(a) If the Department determines that source w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'$oid': '6417c99e2d49ca2fefed9522'}</td>\n",
       "      <td>Chapter 15.5. Disinfectant Residuals, Disinfec...</td>\n",
       "      <td>Article 6. Reporting and Recordkeeping Require...</td>\n",
       "      <td>§ 64537.6. Disinfection Byproduct Precursors a...</td>\n",
       "      <td>(a) Systems required to meet the enhanced coag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>{'$oid': '6417cac62d49ca2fefed9813'}</td>\n",
       "      <td>Chapter 17. Surface Water Treatment</td>\n",
       "      <td>Article 2. Treatment Technique Requirements, W...</td>\n",
       "      <td>§ 64653. Filtration.</td>\n",
       "      <td>(a) All approved surface water utilized by a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>{'$oid': '6417cac62d49ca2fefed9814'}</td>\n",
       "      <td>Chapter 17. Surface Water Treatment</td>\n",
       "      <td>Article 2. Treatment Technique Requirements, W...</td>\n",
       "      <td>§ 64652. Treatment Technique Requirements and ...</td>\n",
       "      <td>(a) A supplier using an approved surface water...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>{'$oid': '6417cac62d49ca2fefed9815'}</td>\n",
       "      <td>Chapter 17. Surface Water Treatment</td>\n",
       "      <td>Article 3. Monitoring Requirements</td>\n",
       "      <td>§ 64655. Filtration Monitoring.</td>\n",
       "      <td>(a) To determine compliance with the performan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>{'$oid': '6417cac72d49ca2fefed9816'}</td>\n",
       "      <td>Chapter 17. Surface Water Treatment</td>\n",
       "      <td>Article 3. Monitoring Requirements</td>\n",
       "      <td>§ 64654.8. Source, Raw, Settled, and Recycled ...</td>\n",
       "      <td>(a) A supplier shall comply with the source mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>{'$oid': '6417cac72d49ca2fefed9817'}</td>\n",
       "      <td>Chapter 17. Surface Water Treatment</td>\n",
       "      <td>Article 2. Treatment Technique Requirements, W...</td>\n",
       "      <td>§ 64652.5. Criteria for Avoiding Filtration.</td>\n",
       "      <td>(a) A supplier that uses an approved surface w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>562 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      _id  \\\n",
       "2    {'$oid': '6417c99c2d49ca2fefed951e'}   \n",
       "3    {'$oid': '6417c99c2d49ca2fefed951f'}   \n",
       "4    {'$oid': '6417c99c2d49ca2fefed9520'}   \n",
       "5    {'$oid': '6417c99d2d49ca2fefed9521'}   \n",
       "6    {'$oid': '6417c99e2d49ca2fefed9522'}   \n",
       "..                                    ...   \n",
       "759  {'$oid': '6417cac62d49ca2fefed9813'}   \n",
       "760  {'$oid': '6417cac62d49ca2fefed9814'}   \n",
       "761  {'$oid': '6417cac62d49ca2fefed9815'}   \n",
       "762  {'$oid': '6417cac72d49ca2fefed9816'}   \n",
       "763  {'$oid': '6417cac72d49ca2fefed9817'}   \n",
       "\n",
       "                                               chapter  \\\n",
       "2                        Chapter 17.5. Lead and Copper   \n",
       "3                        Chapter 17.5. Lead and Copper   \n",
       "4                        Chapter 17.5. Lead and Copper   \n",
       "5                        Chapter 17.5. Lead and Copper   \n",
       "6    Chapter 15.5. Disinfectant Residuals, Disinfec...   \n",
       "..                                                 ...   \n",
       "759                Chapter 17. Surface Water Treatment   \n",
       "760                Chapter 17. Surface Water Treatment   \n",
       "761                Chapter 17. Surface Water Treatment   \n",
       "762                Chapter 17. Surface Water Treatment   \n",
       "763                Chapter 17. Surface Water Treatment   \n",
       "\n",
       "                                               article  \\\n",
       "2    Article 8. Lead Service Line Requirements for ...   \n",
       "3    Article 7. Public Education Program for Lead A...   \n",
       "4    Article 8. Lead Service Line Requirements for ...   \n",
       "5    Article 6. Source Water Requirements for Actio...   \n",
       "6    Article 6. Reporting and Recordkeeping Require...   \n",
       "..                                                 ...   \n",
       "759  Article 2. Treatment Technique Requirements, W...   \n",
       "760  Article 2. Treatment Technique Requirements, W...   \n",
       "761                 Article 3. Monitoring Requirements   \n",
       "762                 Article 3. Monitoring Requirements   \n",
       "763  Article 2. Treatment Technique Requirements, W...   \n",
       "\n",
       "                                                 title  \\\n",
       "2              § 64688. Lead Service Line Replacement.   \n",
       "3    § 64687. Lead Public Education Program Content...   \n",
       "4                 § 64689. Lead Service Line Sampling.   \n",
       "5    § 64686. Requirements Subsequent to the Depart...   \n",
       "6    § 64537.6. Disinfection Byproduct Precursors a...   \n",
       "..                                                 ...   \n",
       "759                               § 64653. Filtration.   \n",
       "760  § 64652. Treatment Technique Requirements and ...   \n",
       "761                    § 64655. Filtration Monitoring.   \n",
       "762  § 64654.8. Source, Raw, Settled, and Recycled ...   \n",
       "763       § 64652.5. Criteria for Avoiding Filtration.   \n",
       "\n",
       "                                         paragraphText  \n",
       "2    (a) A system shall replace lead service lines ...  \n",
       "3    (a) Each system with a lead action level excee...  \n",
       "4    (a) Each lead service line sample shall be one...  \n",
       "5    (a) If the Department determines that source w...  \n",
       "6    (a) Systems required to meet the enhanced coag...  \n",
       "..                                                 ...  \n",
       "759  (a) All approved surface water utilized by a s...  \n",
       "760  (a) A supplier using an approved surface water...  \n",
       "761  (a) To determine compliance with the performan...  \n",
       "762  (a) A supplier shall comply with the source mo...  \n",
       "763  (a) A supplier that uses an approved surface w...  \n",
       "\n",
       "[562 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"./regItems.json\")\n",
    "df = df.replace(to_replace=\"\", value=np.nan).dropna(axis=0) # remove null values\n",
    "# df['paragraphText'] = df['paragraphText'].str.replace(\"OLD SECTION.*\", \"\", regex=True) # remove any dirty words\n",
    "# df['paragraphText'] = df['paragraphText'].str.replace(\"[a-zA-z]\\d\\w+\", \". \", regex=True)\n",
    "# df['paragraphText'] = df['paragraphText'].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4BFih0OfttbN",
    "outputId": "1748b537-010d-4093-96bb-4fbac8f62588"
   },
   "outputs": [],
   "source": [
    "data = df['paragraphText'].tolist()\n",
    "# Prepare your data and convert it into a format that Llama Index can understand\n",
    "# This example assumes that your data is a list of strings\n",
    "formatted_data = [{'text': doc} for doc in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMem8HMtbMHN"
   },
   "source": [
    "- https://github.com/jerryjliu/llama_index/blob/main/examples/test_wiki/TestNYC_Embeddings.ipynb\n",
    "- https://gpt-index.readthedocs.io/en/latest/how_to/custom_llms.html#example-using-a-custom-llm-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c48s5MuqRQvu",
    "tags": []
   },
   "source": [
    "#### LLM customization with LlamaIndex\n",
    "\n",
    "Note that we need to use the prompt helper to customize the prompt sizes, since every model has a slightly different context length.\n",
    "\n",
    "Note that you may have to adjust the internal prompts to get good performance. Even then, you should be using a sufficiently large LLM to ensure it’s capable of handling the complex queries that LlamaIndex uses internally, so your mileage may vary.\n",
    "\n",
    "A list of all default internal prompts is available here: \n",
    "- https://github.com/jerryjliu/llama_index/blob/main/gpt_index/prompts/default_prompts.py\n",
    "\n",
    "Chat-specific prompts are listed here: \n",
    "- https://github.com/jerryjliu/llama_index/blob/main/gpt_index/prompts/chat_prompts.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "q0BnWyKTAExC"
   },
   "outputs": [],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from llama_index import LLMPredictor, GPTSimpleVectorIndex, PromptHelper, ServiceContext\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "from IPython.display import Markdown\n",
    "from typing import Optional, List, Mapping, Any\n",
    "\n",
    "# define prompt helper\n",
    "# set maximum input size\n",
    "max_input_size = 2048\n",
    "# set number of output tokens\n",
    "num_output = 512\n",
    "# set maximum chunk overlap\n",
    "max_chunk_overlap = 20\n",
    "prompt_helper = PromptHelper(max_input_size, num_output, max_chunk_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "iLgu2AszGy5E"
   },
   "outputs": [],
   "source": [
    "# 2. Load the BigScience Bloomz model and tokenizer\n",
    "model_name = \"bigscience/bloom-560m\" # \"bigscience/bloomz\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, config='T5Config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GUpSV_StB1r5"
   },
   "outputs": [],
   "source": [
    "class CustomLLM(LLM):\n",
    "    # 3. Create the pipeline for question answering\n",
    "    pipeline = pipeline(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        task=\"text-generation\",\n",
    "        # device=0, # GPU device number\n",
    "        max_length=512,\n",
    "        do_sample=True,\n",
    "        top_p=0.95,\n",
    "        top_k=50,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        prompt_length = len(prompt)\n",
    "        response = self.pipeline(prompt, max_new_tokens=num_output)[0][\"generated_text\"]\n",
    "\n",
    "        # only return newly generated tokens\n",
    "        return response[prompt_length:]\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        return {\"name_of_model\": self.model_name}\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZG7mhvWFB-6S"
   },
   "outputs": [],
   "source": [
    "#define our llm\n",
    "llm_predictor = LLMPredictor(llm=CustomLLM())\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataset using data loaders from llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import download_loader, Document\n",
    "from pathlib import Path\n",
    "# Load and index the dataset using Llama-index\n",
    "\n",
    "# store all versions of documents and vector indices\n",
    "allDocs = []\n",
    "indices = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vector index by creating Documents manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "psENaxPQQjeI"
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# original data loader after cleaning in pd\n",
    "pdDocs = [Document(d) for d in data]\n",
    "allDocs.append(pdDocs)\n",
    "\n",
    "index = GPTSimpleVectorIndex.from_documents(pdDocs, service_context=service_context)\n",
    "index.save_to_disk('./indices/pdIndex.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vector index by using simple directory data loader \n",
    "The data loader can read in pdf files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# using simple directory data loader\n",
    "SimpleDirectoryReader = download_loader(\"SimpleDirectoryReader\")\n",
    "simpleDirLoader = SimpleDirectoryReader(input_dir=\"./data/pdf\", recursive=True, exclude_hidden=True)\n",
    "simpleDocs = simpleDirLoader.load_data()\n",
    "allDocs.append(simpleDocs)\n",
    "\n",
    "index = GPTSimpleVectorIndex.from_documents(simpleDocs, service_context=service_context)\n",
    "index.save_to_disk('./indices/simpleIndex.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/facebookresearch/detectron2.git\n",
    "# !pip install -e detectron2\n",
    "# !pip install unstructured[local-inference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using unstructured data loader\n",
    "# UnstructuredReader = download_loader(\"UnstructuredReader\", refresh_cache=True)\n",
    "# unstructuredLoader = UnstructuredReader()\n",
    "# unstructuredDocs = unstructuredLoader.load_data(file=Path(f'./data/pdf/calregs.pdf'), split_documents=False)\n",
    "# allDocs.append(unstructuredDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"from Table 64423-A, if monthly population served is 1000, what is the range of service connections and minimum number of samples per month?\", \n",
    "          \"what is the maximum contaminant level of aluminum that public water system shall comply?\",\n",
    "          \"if monthly population served is 500, what is the range of service connections and minimum number of samples per month?\",\n",
    "          \"if monthly population served is 4000, what is the minimum number of samples per month?\",\n",
    "          \"what will the PWS need to do if there is a violation in lead concentration?\",\n",
    "          \"How do we determine how many samples a PWS will need to take for lead?\",\n",
    "          \"What is the difference between a level 1 and 2 assessments?\",\n",
    "          \"What is a level 2 assessment?\",\n",
    "          \"What is a level 1 assessment?\",\n",
    "          \"What is DLR?\",\n",
    "          \"What does DLR stand for?\",\n",
    "          \"what is the exact meaning of the water treatment facility?\",\n",
    "          \"What are some requirements an applicant should have before taking the T2 operator exam?\",\n",
    "          \"what does the term State Board stands for?\",\n",
    "          \"what does awwa abbreviation mean?\",\n",
    "          \"what is AWWA?\", \"what is cross-connection?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load indices\n",
    "pdIndex = GPTSimpleVectorIndex.load_from_disk('./indices/pdIndex.json')\n",
    "simpleIndex = GPTSimpleVectorIndex.load_from_disk('./indices/simpleIndex.json')\n",
    "\n",
    "indices.update({\"pdIndex\": pdIndex})\n",
    "indices.update({\"simpleIndex\": simpleIndex})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 98 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 7 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 3598 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 7 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "DLR stands for \"Detection Limit for Reporting\".</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "DLR stands for Detection Limit for Purposes of Reporting.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdResponse = pdIndex.query(\"What does DLR stand for?\")\n",
    "simpleResponse = simpleIndex.query(\"What does DLR stand for?\")\n",
    "display(Markdown(f\"<b>{pdResponse}</b>\"))\n",
    "display(Markdown(f\"<b>{simpleResponse}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: from Table 64423-A, if monthly population served is 1000, what is the range of service connections and minimum number of samples per month?\n",
      "pdIndex's token usage:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 1925 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 30 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdIndex response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "The range of service connections for a monthly population served of 1000 is 401 to 890, and the minimum number of samples per month is 2.</b><br />"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpleIndex's token usage:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 3670 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 30 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpleIndex response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "The range of service connections is fewer than 10,000 and the minimum number of samples per month is 3.</b><br />"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "----------------------------------------\n",
      "query: what is the maximum contaminant level of aluminum that public water system shall comply?\n",
      "pdIndex's token usage:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 245 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 16 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdIndex response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "The maximum contaminant level of aluminum that public water systems shall comply with is 1 mg/L.</b><br />"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpleIndex's token usage:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 3737 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 16 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpleIndex response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "There is no maximum contaminant level of aluminum specified in the context information.</b><br />"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "----------------------------------------\n",
      "query: if monthly population served is 500, what is the range of service connections and minimum number of samples per month?\n",
      "pdIndex's token usage:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 1917 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 22 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdIndex response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "The range of service connections for a monthly population served of 500 is 401 to 890, and the minimum number of samples per month is 2.</b><br />"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpleIndex's token usage:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 3664 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 22 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpleIndex response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "The range of service connections is 34,301 to 46,400 and the minimum number of samples per month is 100.</b><br />"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "----------------------------------------\n",
      "query: if monthly population served is 4000, what is the minimum number of samples per month?\n",
      "pdIndex's token usage:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 1884 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 17 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdIndex response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "30</b><br />"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpleIndex's token usage:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 3704 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 17 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpleIndex response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "The minimum number of samples per month for a public water system serving 4,000 persons is four. This is based on the information provided in §64423.1(a), which states that a public water system must designate each sample as routine, repeat, replacement, or \"other\" and have each sample analyzed for total coliforms.</b><br />"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "----------------------------------------\n",
      "query: what will the PWS need to do if there is a violation in lead concentration?\n",
      "pdIndex's token usage:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 385 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 17 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdIndex response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "If there is a violation in lead concentration, the PWS will need to collect one lead and copper source water sample from each entry point to the distribution system that is representative of the source or combined sources and is collected after any treatment, if treatment is applied before distribution. They will also need to submit a written recommendation to the Department for the installation and operation of a source water treatment (ion exchange, reverse osmosis, lime softening, or coagulation/filtration) or demonstrate that source water treatment is not needed to minimize lead and copper levels at users' taps. Finally, they will need to submit any additional information requested by the Department to aid in its determination of whether source water treatment is necessary to minimize lead and copper levels in water delivered to users' taps.</b><br />"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpleIndex's token usage:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 3678 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 17 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpleIndex response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "If a water test indicates that the drinking water drawn from a tap in the PWS's home contains lead above 15 ppb, then the PWS will need to take the following precautions: let the water run from the tap before using it for drinking or cooking any time the water in a tap has not been used for several hours; use cold water for drinking, cooking, and preparing baby formula; and consider using a filter certified to remove lead. The PWS may also need to replace the portion of each lead service line that they own if the line contributes lead concentrations of 15 ppb or more after they have completed the comprehensive treatment program.</b><br />"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "----------------------------------------\n",
      "query: How do we determine how many samples a PWS will need to take for lead?\n",
      "pdIndex's token usage:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 609 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 17 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdIndex response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "The number of samples a PWS will need to take for lead will depend on the system's 90th percentile levels for lead and copper, the difference between the 90th percentile tap sampling lead level and the highest source water monitoring result, and the source water lead levels. If the system has 90th percentile levels that do not exceed 0.005 mg/L for lead and 0.65 mg/L for copper for two consecutive periods, it may reduce the sampling to once every three years at the reduced number of sites. If the system does not meet the criteria in paragraph (1), after two consecutive periods with no action level exceedance, the frequency may be reduced to annually at the reduced number of sites, if the system receives written approval from the Department. If the system demonstrates for two consecutive periods that the difference between the 90th percentile tap sampling lead level and the highest source water monitoring result for each period is less than the reporting level for purposes of reporting (DLR), or that the source water lead levels are below the method detection level of 0.001 mg/L and the 90th percentile lead level is equal to or less than the DLR for each period, the system shall conduct tap sampling once every three years.</b><br />"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpleIndex's token usage:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 3731 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 17 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpleIndex response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "The number of samples a public water system (PWS) will need to take for lead will be determined by the requirements of §64689. Lead Service Line Sampling. This section states that each lead service line sample shall be one liter in volume and have stood motionless in the lead service line for at least six hours, but not more than twelve. The number of samples will depend on the size of the lead service line and the number of taps that need to be sampled.</b><br />"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "----------------------------------------\n",
      "query: What is the difference between a level 1 and 2 assessments?\n",
      "pdIndex's token usage:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 221 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 12 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdIndex response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "The difference between a Level 1 and Level 2 assessment is that a Level 2 assessment provides a more detailed examination of the system than a Level 1 assessment. This includes a more comprehensive investigation and review of available information, additional internal and external resources, and other relevant practices to identify the possible presence of sanitary defects, defects in distribution system coliform monitoring practices, and (when possible) the likely reason that the system triggered the assessment.</b><br />"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpleIndex's token usage:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 3807 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 12 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpleIndex response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "A Level 1 assessment is conducted to identify the possible presence of sanitary defects and defects in distribution system coliform monitoring practices. It includes a review and identification of the minimum elements in subparagraphs (A) through (E) and shall describe sanitary defects detected (and if applicable, may note no sanitary defects were detected), corrective actions completed, and a proposed timetable for any corrective actions not already completed. \n",
       "\n",
       "A Level 2 assessment is conducted to identify the possible presence of sanitary defects and defects in distribution system coliform monitoring practices. It includes a review and identification of the minimum elements in subsections (a)(2)(A) through (E) to identify the possible presence of sanitary defects and defects in distribution system coliform monitoring practices. It must also describe sanitary defects detected (and if applicable, may note no sanitary defects were detected), corrective actions completed, and a proposed timetable for any corrective actions not already completed.</b><br />"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "----------------------------------------\n",
      "query: What is a level 2 assessment?\n",
      "pdIndex's token usage:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 207 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 7 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdIndex response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "A Level 2 assessment is an evaluation that provides a more detailed examination of a system than a Level 1 assessment. It involves a comprehensive investigation and review of available information, additional internal and external resources, and other relevant practices to identify the possible presence of sanitary defects, defects in distribution system coliform monitoring practices, and (when possible) the likely reason that the system triggered the assessment.</b><br />"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpleIndex's token usage:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 3627 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 7 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpleIndex response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "A Level 2 assessment is an assessment conducted to identify potential problems in water treatment or distribution. It is used to identify problems and take corrective actions to address any issues that are found.</b><br />"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for query in queries[0: 8]:\n",
    "    print(f\"query: {query}\")\n",
    "    for name, index in indices.items():\n",
    "        print(f\"{name}'s token usage:\")\n",
    "        response = index.query(query)\n",
    "        print(f\"{name} response:\")\n",
    "        display(Markdown(f\"<b>{response}</b><br />\"))\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"----------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
